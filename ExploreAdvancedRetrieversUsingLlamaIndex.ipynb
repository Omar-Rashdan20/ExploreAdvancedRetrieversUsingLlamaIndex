{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Omar-Rashdan20/ExploreAdvancedRetrieversUsingLlamaIndex/blob/main/ExploreAdvancedRetrieversUsingLlamaIndex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga96GOxa_XvG"
      },
      "source": [
        "# **Explore Advanced Retrievers in LlamaIndex**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpClJ4lY_XvJ"
      },
      "source": [
        "### Installing Required Libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sdU-I6E_XvK"
      },
      "outputs": [],
      "source": [
        "!pip install -U \\\n",
        "llama-index \\\n",
        "llama-index-llms-gemini \\\n",
        "llama-index-retrievers-bm25 \\\n",
        "llama-index-embeddings-huggingface \\\n",
        "sentence-transformers \\\n",
        "rank-bm25 \\\n",
        "PyStemmer \\\n",
        "google-generativeai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOTICAmc_XvK"
      },
      "source": [
        "### Importing Required Libraries\n",
        "\n",
        "We begin by importing all necessary libraries and modules for our advanced retriever demonstrations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVDJ4_bj_XvL"
      },
      "outputs": [],
      "source": [
        "# Core LlamaIndex imports\n",
        "from llama_index.core import (\n",
        "    VectorStoreIndex,\n",
        "    Document,\n",
        "    SimpleDirectoryReader,\n",
        "    Settings,\n",
        "    SummaryIndex,\n",
        "    StorageContext\n",
        ")\n",
        "\n",
        "# LLM and Embedding imports\n",
        "from llama_index.llms.gemini import Gemini\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "# Retriever imports\n",
        "from llama_index.retrievers.bm25 import BM25Retriever\n",
        "from llama_index.core.retrievers import (\n",
        "    QueryFusionRetriever,\n",
        "    AutoMergingRetriever,\n",
        "    RecursiveRetriever\n",
        ")\n",
        "\n",
        "# Node parsing and processing\n",
        "from llama_index.core.node_parser import (\n",
        "    HierarchicalNodeParser,\n",
        "    SentenceSplitter\n",
        ")\n",
        "\n",
        "# Schema and response types\n",
        "from llama_index.core.schema import (\n",
        "    NodeWithScore,\n",
        "    TextNode,\n",
        "    IndexNode\n",
        ")\n",
        "\n",
        "from llama_index.core.response_synthesizers import (\n",
        "    get_response_synthesizer\n",
        ")\n",
        "\n",
        "# Query engine\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "\n",
        "# Standard library imports\n",
        "import os\n",
        "from typing import List\n",
        "import Stemmer\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "import os\n",
        "\n",
        "client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "for model in client.models.list():\n",
        "    print(model.name)\n"
      ],
      "metadata": {
        "id": "WkqClAC6DjB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUQ_1Jzr_XvL"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Load API key securely from Colab Secrets\n",
        "api_key = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "if not api_key:\n",
        "    raise ValueError(\"GOOGLE_API_KEY not found in Colab Secrets.\")\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
        "\n",
        "\n",
        "# LlamaIndex Imports\n",
        "from llama_index.llms.gemini import Gemini\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core import Settings\n",
        "\n",
        "\n",
        "# Initialize Gemini LLM\n",
        "llm = Gemini(\n",
        "    model=\"models/gemini-2.5-flash\",   # or \"gemini-1.5-pro\"\n",
        "    temperature=0.1\n",
        ")\n",
        "\n",
        "# Initialize embedding model\n",
        "embed_model = HuggingFaceEmbedding(\n",
        "    model_name=\"BAAI/bge-small-en-v1.5\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# Configure global settings\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model\n",
        "Settings.chunk_size = 512\n",
        "Settings.chunk_overlap = 50\n",
        "\n",
        "\n",
        "print(\"✓ Gemini LLM initialized successfully!\")\n",
        "print(f\"✓ Model: {llm.model}\")\n",
        "print(f\"✓ Embedding Model: {embed_model.model_name}\")\n",
        "print(f\"✓ Chunk Size: {Settings.chunk_size}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg7Fprfb_XvM"
      },
      "source": [
        "### Sample Data Setup\n",
        "\n",
        "Let's create a comprehensive sample dataset that demonstrates the capabilities of different retriever types. We'll use multiple documents covering various topics to showcase different retrieval patterns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGttagvO_XvM"
      },
      "outputs": [],
      "source": [
        "# Create sample documents for testing\n",
        "documents = [\n",
        "    Document(\n",
        "        text=\"\"\"Machine Learning Fundamentals\n",
        "\n",
        "        Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed. It focuses on developing computer programs that can access data and use it to learn for themselves.\n",
        "\n",
        "        The process of learning begins with observations or data, such as examples, direct experience, or instruction, in order to look for patterns in data and make better decisions in the future. The primary aim is to allow computers to learn automatically without human intervention or assistance.\n",
        "        \"\"\",\n",
        "        metadata={\"topic\": \"ML Basics\", \"difficulty\": \"beginner\"}\n",
        "    ),\n",
        "    Document(\n",
        "        text=\"\"\"Types of Machine Learning\n",
        "\n",
        "        There are three main types of machine learning:\n",
        "\n",
        "        1. Supervised Learning: The algorithm learns from labeled training data, helping predict outcomes for unforeseen data. Common applications include classification and regression tasks.\n",
        "\n",
        "        2. Unsupervised Learning: The algorithm learns patterns from unlabeled data. The system tries to learn without a teacher. Common applications include clustering and dimensionality reduction.\n",
        "\n",
        "        3. Reinforcement Learning: The algorithm learns through trial and error, receiving rewards or penalties for actions. It's commonly used in robotics, gaming, and navigation.\n",
        "        \"\"\",\n",
        "        metadata={\"topic\": \"ML Types\", \"difficulty\": \"intermediate\"}\n",
        "    ),\n",
        "    Document(\n",
        "        text=\"\"\"Neural Networks Architecture\n",
        "\n",
        "        Neural networks are computing systems inspired by biological neural networks in animal brains. They consist of interconnected nodes (neurons) organized in layers:\n",
        "\n",
        "        - Input Layer: Receives the initial data\n",
        "        - Hidden Layers: Process information through weighted connections\n",
        "        - Output Layer: Produces the final result\n",
        "\n",
        "        Deep learning uses neural networks with multiple hidden layers, enabling the learning of complex patterns. Each neuron applies an activation function to introduce non-linearity, allowing the network to learn sophisticated relationships in data.\n",
        "        \"\"\",\n",
        "        metadata={\"topic\": \"Deep Learning\", \"difficulty\": \"advanced\"}\n",
        "    ),\n",
        "    Document(\n",
        "        text=\"\"\"Data Preprocessing Techniques\n",
        "\n",
        "        Data preprocessing is a crucial step in machine learning pipelines:\n",
        "\n",
        "        - Data Cleaning: Remove noise, handle missing values, and eliminate duplicates\n",
        "        - Normalization: Scale features to a standard range\n",
        "        - Feature Engineering: Create new features from existing data\n",
        "        - Encoding: Convert categorical variables to numerical format\n",
        "        - Data Splitting: Divide data into training, validation, and test sets\n",
        "\n",
        "        Proper preprocessing significantly impacts model performance and can be the difference between a successful and unsuccessful machine learning project.\n",
        "        \"\"\",\n",
        "        metadata={\"topic\": \"Data Processing\", \"difficulty\": \"intermediate\"}\n",
        "    ),\n",
        "    Document(\n",
        "        text=\"\"\"Model Evaluation Metrics\n",
        "\n",
        "        Evaluating machine learning models requires appropriate metrics:\n",
        "\n",
        "        For Classification:\n",
        "        - Accuracy: Overall correctness of predictions\n",
        "        - Precision: Quality of positive predictions\n",
        "        - Recall: Coverage of actual positive cases\n",
        "        - F1 Score: Harmonic mean of precision and recall\n",
        "\n",
        "        For Regression:\n",
        "        - Mean Squared Error (MSE): Average squared differences\n",
        "        - Root Mean Squared Error (RMSE): Square root of MSE\n",
        "        - R-squared: Proportion of variance explained\n",
        "        - Mean Absolute Error (MAE): Average absolute differences\n",
        "        \"\"\",\n",
        "        metadata={\"topic\": \"Evaluation\", \"difficulty\": \"intermediate\"}\n",
        "    )\n",
        "]\n",
        "\n",
        "print(f\"Created {len(documents)} sample documents\")\n",
        "print(\"\\nDocument topics:\")\n",
        "for i, doc in enumerate(documents, 1):\n",
        "    print(f\"{i}. {doc.metadata['topic']} ({doc.metadata['difficulty']} level)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewvsKe1y_XvM"
      },
      "source": [
        "## Background\n",
        "\n",
        "Before diving into implementation, let's understand the theoretical foundation of advanced retrievers and their role in RAG systems.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Srpk7gvI_XvM"
      },
      "source": [
        "### What are Advanced Retrievers?\n",
        "\n",
        "Advanced retrievers are sophisticated mechanisms that go beyond simple similarity search to find the most relevant information from a knowledge base. While basic retrievers rely solely on vector similarity, advanced retrievers employ multiple strategies:\n",
        "\n",
        "**Core Capabilities:**\n",
        "- **Multi-Strategy Search**: Combine semantic, keyword, and structural approaches\n",
        "- **Hierarchical Understanding**: Navigate document structures intelligently\n",
        "- **Query Enhancement**: Generate and fuse multiple query variations\n",
        "- **Context Preservation**: Maintain document hierarchy and relationships\n",
        "- **Adaptive Ranking**: Use sophisticated scoring mechanisms\n",
        "\n",
        "**Key Differences from Basic Retrieval:**\n",
        "1. Basic: Single embedding similarity → Advanced: Multiple retrieval strategies\n",
        "2. Basic: Flat document structure → Advanced: Hierarchical understanding\n",
        "3. Basic: Single query → Advanced: Query expansion and fusion\n",
        "4. Basic: Fixed chunk size → Advanced: Dynamic context merging\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e24jpP2p_XvM"
      },
      "source": [
        "### Why are Advanced Retrievers Important?\n",
        "\n",
        "Advanced retrievers address critical limitations in production RAG systems:\n",
        "\n",
        "**1. Improved Recall and Precision**\n",
        "- Combine semantic and keyword search to catch different query types\n",
        "- Reduce false negatives through query expansion\n",
        "- Minimize false positives with better ranking\n",
        "\n",
        "**2. Better Context Understanding**\n",
        "- Preserve document structure and hierarchy\n",
        "- Maintain relationships between sections\n",
        "- Provide appropriate context windows\n",
        "\n",
        "**3. Handling Complex Queries**\n",
        "- Multi-faceted questions requiring different retrieval strategies\n",
        "- Queries that benefit from multiple perspectives\n",
        "- Technical queries needing exact keyword matches\n",
        "\n",
        "**4. Production Reliability**\n",
        "- Fallback mechanisms for edge cases\n",
        "- Consistent performance across query types\n",
        "- Scalable to large document collections\n",
        "\n",
        "**Real-World Impact:**\n",
        "- Customer Support: 40% improvement in answer relevance\n",
        "- Legal Research: 60% reduction in missed relevant cases\n",
        "- Technical Documentation: 50% faster information retrieval\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vukvDqvr_XvN"
      },
      "source": [
        "### Index Types Overview\n",
        "\n",
        "LlamaIndex supports various index types, each optimized for different retrieval patterns:\n",
        "\n",
        "**1. Vector Store Index**\n",
        "- **Best For**: Semantic similarity search\n",
        "- **How It Works**: Embeds documents and queries into vector space\n",
        "- **Strengths**: Captures meaning and context\n",
        "- **Use Cases**: General question answering, conceptual queries\n",
        "\n",
        "**2. Keyword/BM25 Index**\n",
        "- **Best For**: Exact term matching\n",
        "- **How It Works**: Statistical ranking based on term frequency\n",
        "- **Strengths**: Precise keyword retrieval, no embedding overhead\n",
        "- **Use Cases**: Technical documentation, legal search, code retrieval\n",
        "\n",
        "**3. Summary Index**\n",
        "- **Best For**: Document-level retrieval\n",
        "- **How It Works**: Creates summaries for document selection\n",
        "- **Strengths**: Intelligent document filtering\n",
        "- **Use Cases**: Multi-document QA, research papers, long-form content\n",
        "\n",
        "**4. Hierarchical Index**\n",
        "- **Best For**: Structured documents\n",
        "- **How It Works**: Maintains parent-child relationships\n",
        "- **Strengths**: Context preservation, dynamic merging\n",
        "- **Use Cases**: Books, technical manuals, structured reports\n",
        "\n",
        "**Choosing the Right Index:**\n",
        "- Single strategy → Simple queries, homogeneous content\n",
        "- Hybrid approach → Production systems, diverse query types\n",
        "- Multi-index → Large-scale systems, specialized content types\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KZiQTXv_XvN"
      },
      "source": [
        "## Core Retriever Demonstrations\n",
        "\n",
        "Now let's implement and test each retriever type with practical examples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPk_jOL4_XvN"
      },
      "source": [
        "### 1. Vector Index Retriever - The Foundation\n",
        "\n",
        "The Vector Index Retriever is the most common retrieval method, using semantic similarity to find relevant documents.\n",
        "\n",
        "**How It Works:**\n",
        "1. Documents are split into chunks and embedded into vectors\n",
        "2. Queries are embedded using the same model\n",
        "3. Cosine similarity finds the closest vectors\n",
        "4. Top-k most similar chunks are retrieved\n",
        "\n",
        "**Strengths:**\n",
        "- Captures semantic meaning beyond keywords\n",
        "- Handles paraphrasing and synonyms well\n",
        "- Good for conceptual questions\n",
        "\n",
        "**Limitations:**\n",
        "- May miss exact keyword matches\n",
        "- Embedding quality dependent\n",
        "- Computational overhead for embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVVlmcp7_XvN"
      },
      "outputs": [],
      "source": [
        "# Create Vector Store Index\n",
        "vector_index = VectorStoreIndex.from_documents(\n",
        "    documents,\n",
        "    show_progress=True\n",
        ")\n",
        "\n",
        "# Get the retriever\n",
        "vector_retriever = vector_index.as_retriever(\n",
        "    similarity_top_k=3  # Retrieve top 3 most similar chunks\n",
        ")\n",
        "\n",
        "# Test with a semantic query\n",
        "query = \"How do computers learn without being programmed?\"\n",
        "retrieved_nodes = vector_retriever.retrieve(query)\n",
        "\n",
        "print(f\"Query: {query}\\n\")\n",
        "print(f\"Retrieved {len(retrieved_nodes)} nodes:\\n\")\n",
        "\n",
        "for i, node in enumerate(retrieved_nodes, 1):\n",
        "    print(f\"Result {i} (Score: {node.score:.4f}):\")\n",
        "    print(f\"Topic: {node.metadata.get('topic', 'N/A')}\")\n",
        "    print(f\"Text preview: {node.text[:200]}...\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4dHDQvV_XvN"
      },
      "source": [
        "### 2. BM25 Retriever - Advanced Keyword-Based Search\n",
        "\n",
        "BM25 (Best Matching 25) is a probabilistic ranking function that excels at keyword-based retrieval.\n",
        "\n",
        "**How It Works:**\n",
        "1. Tokenizes documents and queries\n",
        "2. Applies stemming to normalize words\n",
        "3. Calculates term frequency (TF) and inverse document frequency (IDF)\n",
        "4. Ranks documents using BM25 scoring formula\n",
        "\n",
        "**Strengths:**\n",
        "- Excellent for exact term matching\n",
        "- No embedding model required\n",
        "- Fast and efficient\n",
        "- Great for technical/domain-specific terms\n",
        "\n",
        "**Use Cases:**\n",
        "- Legal document search\n",
        "- Code retrieval\n",
        "- Technical documentation\n",
        "- When exact terminology matters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0mJdJc4_XvN"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.retrievers.bm25 import BM25Retriever\n",
        "import Stemmer\n",
        "\n",
        "parser = SentenceSplitter(\n",
        "    chunk_size=115,\n",
        "    chunk_overlap=15\n",
        ")\n",
        "\n",
        "nodes = parser.get_nodes_from_documents(documents)\n",
        "\n",
        "print(f\"Created {len(nodes)} nodes for BM25 indexing.\\n\")\n",
        "\n",
        "\n",
        "# 2)Initialize BM25 Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_defaults(\n",
        "    nodes=nodes,\n",
        "    similarity_top_k=3,\n",
        "    stemmer=Stemmer.Stemmer(\"english\"),\n",
        "    language=\"english\"\n",
        ")\n",
        "\n",
        "\n",
        "#Test Query\n",
        "\n",
        "query = \"supervised learning classification regression\"\n",
        "\n",
        "retrieved_nodes = bm25_retriever.retrieve(query)\n",
        "\n",
        "print(f\"Query: {query}\\n\")\n",
        "print(f\"Retrieved {len(retrieved_nodes)} nodes:\\n\")\n",
        "\n",
        "for i, node in enumerate(retrieved_nodes, 1):\n",
        "    print(f\"Result {i} (Score: {node.score:.4f})\")\n",
        "    print(f\"Topic: {node.metadata.get('topic', 'N/A')}\")\n",
        "    print(f\"Text: {node.text}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_I2aj3H_XvN"
      },
      "source": [
        "### 3. Document Summary Index Retrievers\n",
        "\n",
        "Document Summary Index creates summaries of documents and uses them for initial selection, enabling more intelligent document-level retrieval.\n",
        "\n",
        "**How It Works:**\n",
        "1. Generates a summary for each document using an LLM\n",
        "2. Uses summaries for initial document selection\n",
        "3. Retrieves from selected documents\n",
        "\n",
        "**Strengths:**\n",
        "- Intelligent document pre-filtering\n",
        "- Reduces search space\n",
        "- Better for multi-document scenarios\n",
        "\n",
        "**Best For:**\n",
        "- Research paper collections\n",
        "- Multi-document QA\n",
        "- Large document sets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYRZiyoe_XvN"
      },
      "outputs": [],
      "source": [
        "# Create Summary Index\n",
        "summary_index = SummaryIndex.from_documents(\n",
        "    documents,\n",
        "    show_progress=True\n",
        ")\n",
        "\n",
        "# Create query engine from summary index\n",
        "summary_query_engine = summary_index.as_query_engine(\n",
        "    response_mode=\"tree_summarize\"\n",
        ")\n",
        "\n",
        "# Test with a broad query\n",
        "query = \"What are the main concepts in machine learning?\"\n",
        "response = summary_query_engine.query(query)\n",
        "\n",
        "print(f\"Query: {query}\\n\")\n",
        "print(f\"Response: {response}\\n\")\n",
        "print(f\"\\nSource nodes used: {len(response.source_nodes)}\")\n",
        "for i, node in enumerate(response.source_nodes, 1):\n",
        "    print(f\"{i}. {node.metadata.get('topic', 'N/A')}\")\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XriaYiX0_XvO"
      },
      "source": [
        "### 4. Auto-Merging Retriever - Hierarchical Context Preservation\n",
        "\n",
        "Auto-Merging Retriever maintains document hierarchy and intelligently merges chunks when multiple child chunks from the same parent are retrieved.\n",
        "\n",
        "**How It Works:**\n",
        "1. Documents are parsed into hierarchical chunks (parent-child relationships)\n",
        "2. Retrieval happens at the child level (smaller chunks)\n",
        "3. If multiple children from same parent are retrieved, they're merged\n",
        "4. Provides more complete context automatically\n",
        "\n",
        "**Strengths:**\n",
        "- Preserves document structure\n",
        "- Automatic context expansion\n",
        "- Better coherence in responses\n",
        "\n",
        "**Use Cases:**\n",
        "- Books and long-form content\n",
        "- Technical manuals\n",
        "- Structured documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izyEsgwD_XvO"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.node_parser import HierarchicalNodeParser\n",
        "from llama_index.core import StorageContext, VectorStoreIndex\n",
        "from llama_index.core.retrievers import AutoMergingRetriever\n",
        "\n",
        "\n",
        "# Create hierarchical nodes\n",
        "node_parser = HierarchicalNodeParser.from_defaults(\n",
        "    chunk_sizes=[512, 256, 128]\n",
        ")\n",
        "\n",
        "hierarchical_nodes = node_parser.get_nodes_from_documents(documents)\n",
        "\n",
        "print(f\"Created {len(hierarchical_nodes)} hierarchical nodes\\n\")\n",
        "\n",
        "\n",
        "# Create storage context\n",
        "storage_context = StorageContext.from_defaults()\n",
        "storage_context.docstore.add_documents(hierarchical_nodes)\n",
        "\n",
        "\n",
        "# Build vector index\n",
        "hierarchical_index = VectorStoreIndex(\n",
        "    hierarchical_nodes,\n",
        "    storage_context=storage_context\n",
        ")\n",
        "\n",
        "print(\"Vector index built successfully\\n\")\n",
        "\n",
        "\n",
        "# Create auto-merging retriever\n",
        "base_retriever = hierarchical_index.as_retriever(\n",
        "    similarity_top_k=6\n",
        ")\n",
        "\n",
        "auto_merging_retriever = AutoMergingRetriever(\n",
        "    base_retriever,\n",
        "    storage_context=storage_context,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"Auto-merging retriever initialized\\n\")\n",
        "\n",
        "\n",
        "# Test query\n",
        "query = \"Explain the types of machine learning\"\n",
        "\n",
        "retrieved_nodes = auto_merging_retriever.retrieve(query)\n",
        "\n",
        "print(f\"Query: {query}\\n\")\n",
        "print(f\"Retrieved {len(retrieved_nodes)} merged nodes:\\n\")\n",
        "\n",
        "for i, node in enumerate(retrieved_nodes, 1):\n",
        "    print(f\"Node {i}\")\n",
        "    print(f\"Topic: {node.metadata.get('topic', 'N/A')}\")\n",
        "    print(f\"Text Length: {len(node.text)} characters\")\n",
        "    print(f\"Preview: {node.text[:150]}...\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV_fkl5w_XvO"
      },
      "source": [
        "### 5. Recursive Retriever - Multi-Level Reference Following\n",
        "\n",
        "Recursive Retriever can follow references and retrieve from multiple levels of document structure.\n",
        "\n",
        "**How It Works:**\n",
        "1. Initial retrieval from index nodes (high-level references)\n",
        "2. Recursively retrieves from referenced underlying indices\n",
        "3. Aggregates results from multiple levels\n",
        "\n",
        "**Strengths:**\n",
        "- Handles complex document structures\n",
        "- Follows cross-references\n",
        "- Multi-level aggregation\n",
        "\n",
        "**Use Cases:**\n",
        "- Cross-referenced documents\n",
        "- Multi-index systems\n",
        "- Hierarchical knowledge bases\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6KbOyvB_XvO"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.core.schema import IndexNode\n",
        "from llama_index.core.retrievers import RecursiveRetriever\n",
        "\n",
        "\n",
        "# Split documents\n",
        "ml_docs = [doc for doc in documents if \"ML\" in doc.metadata.get(\"topic\", \"\")]\n",
        "advanced_docs = [doc for doc in documents if \"ML\" not in doc.metadata.get(\"topic\", \"\")]\n",
        "\n",
        "\n",
        "# Create sub-indices\n",
        "ml_index = VectorStoreIndex.from_documents(ml_docs)\n",
        "advanced_index = VectorStoreIndex.from_documents(advanced_docs)\n",
        "\n",
        "\n",
        "# Create router nodes\n",
        "router_nodes = [\n",
        "    IndexNode(\n",
        "        text=\"Covers machine learning fundamentals and types including supervised and unsupervised learning.\",\n",
        "        index_id=\"ml_index\"\n",
        "    ),\n",
        "    IndexNode(\n",
        "        text=\"Covers neural networks, preprocessing, and evaluation metrics.\",\n",
        "        index_id=\"advanced_index\"\n",
        "    )\n",
        "]\n",
        "\n",
        "\n",
        "# Create top-level index\n",
        "top_index = VectorStoreIndex(router_nodes)\n",
        "\n",
        "\n",
        "# Create recursive retriever\n",
        "recursive_retriever = RecursiveRetriever(\n",
        "    root_id=\"vector\",\n",
        "    retriever_dict={\n",
        "        \"vector\": top_index.as_retriever(similarity_top_k=1),\n",
        "        \"ml_index\": ml_index.as_retriever(similarity_top_k=3),\n",
        "        \"advanced_index\": advanced_index.as_retriever(similarity_top_k=3),\n",
        "    },\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "\n",
        "# Test query\n",
        "query = \"What is supervised learning?\"\n",
        "\n",
        "results = recursive_retriever.retrieve(query)\n",
        "\n",
        "print(f\"\\nQuery: {query}\\n\")\n",
        "print(f\"Retrieved {len(results)} nodes via recursive routing:\\n\")\n",
        "\n",
        "for i, node in enumerate(results, 1):\n",
        "    print(f\"Node {i}\")\n",
        "    print(f\"Score: {node.score:.4f}\")\n",
        "    print(f\"Topic: {node.metadata.get('topic', 'N/A')}\")\n",
        "    print(f\"Preview: {node.text[:200]}...\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9JqLJM__XvO"
      },
      "source": [
        "### 6. Query Fusion Retriever - Multi-Query Enhancement with Advanced Fusion\n",
        "\n",
        "Query Fusion Retriever generates multiple query variations and combines results using sophisticated fusion techniques.\n",
        "\n",
        "**How It Works:**\n",
        "1. Generates multiple query variations using an LLM\n",
        "2. Retrieves results for each query variation\n",
        "3. Fuses results using one of three strategies:\n",
        "   - **Reciprocal Rank Fusion (RRF)**: Combines based on rank positions\n",
        "   - **Relative Score Fusion**: Normalizes and combines scores\n",
        "   - **Distribution-Based Fusion**: Uses score distributions\n",
        "\n",
        "**Strengths:**\n",
        "- Handles ambiguous queries\n",
        "- Improves recall\n",
        "- Multiple perspectives\n",
        "\n",
        "**Fusion Methods Compared:**\n",
        "\n",
        "**Reciprocal Rank Fusion (RRF):**\n",
        "- Formula: `score = Σ(1 / (k + rank))` where k=60 (typical)\n",
        "- Focuses on rank position, not raw scores\n",
        "- Good when different retrievers have incomparable scores\n",
        "- Example: If doc appears at rank 1 in one query and rank 3 in another:\n",
        "  - RRF score = 1/(60+1) + 1/(60+3) ≈ 0.0164 + 0.0159 = 0.0323\n",
        "\n",
        "**Relative Score Fusion:**\n",
        "- Normalizes scores to [0,1] range for each query\n",
        "- Takes mean of normalized scores across queries\n",
        "- Better when scores are meaningful within each retrieval\n",
        "- Example: Raw scores [0.8, 0.6, 0.4] normalized to [1.0, 0.5, 0.0]\n",
        "\n",
        "**Distribution-Based Fusion:**\n",
        "- Uses statistical distribution of scores\n",
        "- Considers mean and standard deviation\n",
        "- Good for handling outliers and score variance\n",
        "- Example: Weights based on how many standard deviations above mean\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mCiuki4_XvO"
      },
      "outputs": [],
      "source": [
        "# Create query fusion retriever with RRF\n",
        "fusion_retriever_rrf = QueryFusionRetriever(\n",
        "    retrievers=[vector_retriever, bm25_retriever],\n",
        "    similarity_top_k=3,\n",
        "    num_queries=3,  # Generate 3 query variations\n",
        "    mode=\"reciprocal_rerank\",  # RRF fusion\n",
        "    use_async=False,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Test with an ambiguous query\n",
        "query = \"How can I improve model accuracy?\"\n",
        "print(f\"Testing RRF Fusion with query: {query}\\n\")\n",
        "retrieved_nodes_rrf = fusion_retriever_rrf.retrieve(query)\n",
        "\n",
        "print(f\"\\nRetrieved {len(retrieved_nodes_rrf)} nodes with RRF:\\n\")\n",
        "for i, node in enumerate(retrieved_nodes_rrf, 1):\n",
        "    print(f\"Node {i} (Score: {node.score:.4f}):\")\n",
        "    print(f\"Topic: {node.metadata.get('topic', 'N/A')}\")\n",
        "    print(f\"Preview: {node.text[:150]}...\\n\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# Create query fusion retriever with Relative Score Fusion\n",
        "fusion_retriever_relative = QueryFusionRetriever(\n",
        "    retrievers=[vector_retriever, bm25_retriever],\n",
        "    similarity_top_k=3,\n",
        "    num_queries=3,\n",
        "    mode=\"relative_score\",  # Relative score fusion\n",
        "    use_async=False,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(f\"Testing Relative Score Fusion with query: {query}\\n\")\n",
        "retrieved_nodes_relative = fusion_retriever_relative.retrieve(query)\n",
        "\n",
        "print(f\"\\nRetrieved {len(retrieved_nodes_relative)} nodes with Relative Score:\\n\")\n",
        "for i, node in enumerate(retrieved_nodes_relative, 1):\n",
        "    print(f\"Node {i} (Score: {node.score:.4f}):\")\n",
        "    print(f\"Topic: {node.metadata.get('topic', 'N/A')}\")\n",
        "    print(f\"Preview: {node.text[:150]}...\\n\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# Create query fusion retriever with Distribution-Based Fusion\n",
        "fusion_retriever_dist = QueryFusionRetriever(\n",
        "    retrievers=[vector_retriever, bm25_retriever],\n",
        "    similarity_top_k=3,\n",
        "    num_queries=3,\n",
        "    mode=\"dist_based_score\",  # Distribution-based fusion\n",
        "    use_async=False,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(f\"Testing Distribution-Based Fusion with query: {query}\\n\")\n",
        "retrieved_nodes_dist = fusion_retriever_dist.retrieve(query)\n",
        "\n",
        "print(f\"\\nRetrieved {len(retrieved_nodes_dist)} nodes with Distribution-Based:\\n\")\n",
        "for i, node in enumerate(retrieved_nodes_dist, 1):\n",
        "    print(f\"Node {i} (Score: {node.score:.4f}):\")\n",
        "    print(f\"Topic: {node.metadata.get('topic', 'N/A')}\")\n",
        "    print(f\"Preview: {node.text[:150]}...\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfuDWLSE_XvO"
      },
      "source": [
        "**Choosing the Right Fusion Mode:**\n",
        "\n",
        "- **Use RRF when**:\n",
        "  - Combining retrievers with different scoring scales\n",
        "  - You trust ranking more than absolute scores\n",
        "  - Scores across retrievers aren't directly comparable\n",
        "\n",
        "- **Use Relative Score when**:\n",
        "  - Scores within each retriever are meaningful\n",
        "  - You want to preserve relative quality differences\n",
        "  - Retrievers have similar scoring mechanisms\n",
        "\n",
        "- **Use Distribution-Based when**:\n",
        "  - Dealing with varying score distributions\n",
        "  - Need to handle outliers gracefully\n",
        "  - Want statistical normalization\n",
        "\n",
        "In practice, **RRF is the most commonly used** as it's robust and works well across different retriever combinations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sflJKm3_XvP"
      },
      "source": [
        "## Summary\n",
        "\n",
        "**Key Concepts:**\n",
        "- **Vector Index Retriever**: Semantic search using embeddings\n",
        "- **BM25 Retriever**: Advanced keyword-based search with TF-IDF improvements\n",
        "- **Document Summary Index**: Intelligent document selection using summaries\n",
        "- **Auto Merging Retriever**: Hierarchical context preservation\n",
        "- **Recursive Retriever**: Multi-level reference following\n",
        "- **Query Fusion Retriever**: Multi-query enhancement with three fusion modes\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "runtime_attributes": {
        "runtime_version": "2026.01"
      },
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}