{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga96GOxa_XvG"
      },
      "source": [
        "# **Explore Advanced Retrievers in LlamaIndex**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpClJ4lY_XvJ"
      },
      "source": [
        "### Installing Required Libraries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sdU-I6E_XvK",
        "outputId": "28d15e59-b7e1-463a-e2ed-fe2182e7f54d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.12/dist-packages (0.14.13)\n",
            "Requirement already satisfied: llama-index-llms-gemini in /usr/local/lib/python3.12/dist-packages (0.6.2)\n",
            "Requirement already satisfied: llama-index-retrievers-bm25 in /usr/local/lib/python3.12/dist-packages (0.6.5)\n",
            "Requirement already satisfied: llama-index-embeddings-huggingface in /usr/local/lib/python3.12/dist-packages (0.6.1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.2)\n",
            "Requirement already satisfied: rank-bm25 in /usr/local/lib/python3.12/dist-packages (0.2.2)\n",
            "Requirement already satisfied: PyStemmer in /usr/local/lib/python3.12/dist-packages (2.2.0.3)\n",
            "Collecting PyStemmer\n",
            "  Using cached PyStemmer-3.0.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.6)\n",
            "Requirement already satisfied: llama-index-cli<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.5.3)\n",
            "Requirement already satisfied: llama-index-core<0.15.0,>=0.14.13 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.14.13)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.5.1)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.9.4)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.7,>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.6.18)\n",
            "Requirement already satisfied: llama-index-readers-file<0.6,>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.5.6)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from llama-index) (0.5.1)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.12/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: pillow<11,>=10.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-llms-gemini) (10.4.0)\n",
            "Requirement already satisfied: bm25s>=0.2.7.post1 in /usr/local/lib/python3.12/dist-packages (from llama-index-retrievers-bm25) (0.2.14)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.36.0)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.29.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.188.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.43.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.12.3)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.27.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.72.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (6.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.0.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.2.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.13.3)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (0.22.1)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (2.4.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (1.2.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows!=2.9.0,<3,>=2 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (2.14.1)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (3.6.1)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (4.5.1)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (82.0.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.13->llama-index) (2.0.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (9.1.2)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (0.12.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from llama-index-core<0.15.0,>=0.14.13->llama-index) (1.17.3)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (2.15.0)\n",
            "Requirement already satisfied: llama-cloud==0.1.35 in /usr/local/lib/python3.12/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.35)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.12/dist-packages (from llama-cloud==0.1.35->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2026.1.4)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (4.13.5)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.7.1)\n",
            "Requirement already satisfied: pandas<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.2.2)\n",
            "Requirement already satisfied: pypdf<7,>=6.1.3 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (6.7.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>3.8.1->llama-index) (2025.11.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.1)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.3.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.22.0)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.12/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.13->llama-index) (1.15.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.8.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.3.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15.0,>=0.14.13->llama-index) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15.0,>=0.14.13->llama-index) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx->llama-index-core<0.15.0,>=0.14.13->llama-index) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.15.0,>=0.14.13->llama-index) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.13->llama-index) (0.4.2)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.54 in /usr/local/lib/python3.12/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.13->llama-index) (3.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.13->llama-index) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json->llama-index-core<0.15.0,>=0.14.13->llama-index) (3.26.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: python-dotenv<2,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from llama-cloud-services>=0.6.54->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (1.17.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.12/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.13->llama-index) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U \\\n",
        "llama-index \\\n",
        "llama-index-llms-gemini \\\n",
        "llama-index-retrievers-bm25 \\\n",
        "llama-index-embeddings-huggingface \\\n",
        "sentence-transformers \\\n",
        "rank-bm25 \\\n",
        "PyStemmer \\\n",
        "google-generativeai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOTICAmc_XvK"
      },
      "source": [
        "### Importing Required Libraries\n",
        "\n",
        "We begin by importing all necessary libraries and modules for our advanced retriever demonstrations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVDJ4_bj_XvL",
        "outputId": "3c8f2ee1-62de-4e93-8ee4-11a2f544953c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Core LlamaIndex imports\n",
        "from llama_index.core import (\n",
        "    VectorStoreIndex,\n",
        "    Document,\n",
        "    SimpleDirectoryReader,\n",
        "    Settings,\n",
        "    SummaryIndex,\n",
        "    StorageContext\n",
        ")\n",
        "\n",
        "# LLM and Embedding imports\n",
        "from llama_index.llms.gemini import Gemini\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "\n",
        "# Retriever imports\n",
        "from llama_index.retrievers.bm25 import BM25Retriever\n",
        "from llama_index.core.retrievers import (\n",
        "    QueryFusionRetriever,\n",
        "    AutoMergingRetriever,\n",
        "    RecursiveRetriever\n",
        ")\n",
        "\n",
        "# Node parsing and processing\n",
        "from llama_index.core.node_parser import (\n",
        "    HierarchicalNodeParser,\n",
        "    SentenceSplitter\n",
        ")\n",
        "\n",
        "# Schema and response types\n",
        "from llama_index.core.schema import (\n",
        "    NodeWithScore,\n",
        "    TextNode,\n",
        "    IndexNode\n",
        ")\n",
        "\n",
        "from llama_index.core.response_synthesizers import (\n",
        "    get_response_synthesizer\n",
        ")\n",
        "\n",
        "# Query engine\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "\n",
        "# Standard library imports\n",
        "import os\n",
        "from typing import List\n",
        "import Stemmer\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "import os\n",
        "\n",
        "client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "for model in client.models.list():\n",
        "    print(model.name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkqClAC6DjB1",
        "outputId": "eb664000-92b3-4fa1-cc96-ac15fe4527e3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-flash-latest\n",
            "models/gemini-flash-lite-latest\n",
            "models/gemini-pro-latest\n",
            "models/gemini-2.5-flash-lite\n",
            "models/gemini-2.5-flash-image\n",
            "models/gemini-2.5-flash-preview-09-2025\n",
            "models/gemini-2.5-flash-lite-preview-09-2025\n",
            "models/gemini-3-pro-preview\n",
            "models/gemini-3-flash-preview\n",
            "models/gemini-3-pro-image-preview\n",
            "models/nano-banana-pro-preview\n",
            "models/gemini-robotics-er-1.5-preview\n",
            "models/gemini-2.5-computer-use-preview-10-2025\n",
            "models/deep-research-pro-preview-12-2025\n",
            "models/gemini-embedding-001\n",
            "models/aqa\n",
            "models/imagen-4.0-generate-preview-06-06\n",
            "models/imagen-4.0-ultra-generate-preview-06-06\n",
            "models/imagen-4.0-generate-001\n",
            "models/imagen-4.0-ultra-generate-001\n",
            "models/imagen-4.0-fast-generate-001\n",
            "models/veo-2.0-generate-001\n",
            "models/veo-3.0-generate-001\n",
            "models/veo-3.0-fast-generate-001\n",
            "models/veo-3.1-generate-preview\n",
            "models/veo-3.1-fast-generate-preview\n",
            "models/gemini-2.5-flash-native-audio-latest\n",
            "models/gemini-2.5-flash-native-audio-preview-09-2025\n",
            "models/gemini-2.5-flash-native-audio-preview-12-2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "AUQ_1Jzr_XvL",
        "outputId": "62e4fe58-0793-49ce-ec54-52bdadcebcca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3520706962.py:20: DeprecationWarning: Call to deprecated class Gemini. (Should use `llama-index-llms-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/llm/google_genai/This package will no longer be supported after version 0.6.2) -- Deprecated since version 0.6.2.\n",
            "  llm = Gemini(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Gemini LLM initialized successfully!\n",
            "✓ Model: models/gemini-2.5-flash\n",
            "✓ Embedding Model: BAAI/bge-small-en-v1.5\n",
            "✓ Chunk Size: 512\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Load API key securely from Colab Secrets\n",
        "api_key = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "if not api_key:\n",
        "    raise ValueError(\"GOOGLE_API_KEY not found in Colab Secrets.\")\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
        "\n",
        "\n",
        "# LlamaIndex Imports\n",
        "from llama_index.llms.gemini import Gemini\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core import Settings\n",
        "\n",
        "\n",
        "# Initialize Gemini LLM\n",
        "llm = Gemini(\n",
        "    model=\"models/gemini-2.5-flash\",   # or \"gemini-1.5-pro\"\n",
        "    temperature=0.1\n",
        ")\n",
        "\n",
        "# Initialize embedding model\n",
        "embed_model = HuggingFaceEmbedding(\n",
        "    model_name=\"BAAI/bge-small-en-v1.5\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "# Configure global settings\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model\n",
        "Settings.chunk_size = 512\n",
        "Settings.chunk_overlap = 50\n",
        "\n",
        "\n",
        "print(\"✓ Gemini LLM initialized successfully!\")\n",
        "print(f\"✓ Model: {llm.model}\")\n",
        "print(f\"✓ Embedding Model: {embed_model.model_name}\")\n",
        "print(f\"✓ Chunk Size: {Settings.chunk_size}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dg7Fprfb_XvM"
      },
      "source": [
        "### Sample Data Setup\n",
        "\n",
        "Let's create a comprehensive sample dataset that demonstrates the capabilities of different retriever types. We'll use multiple documents covering various topics to showcase different retrieval patterns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGttagvO_XvM",
        "outputId": "36d8c2fc-2433-464c-ed80-2faf91a3f2f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 5 sample documents\n",
            "\n",
            "Document topics:\n",
            "1. ML Basics (beginner level)\n",
            "2. ML Types (intermediate level)\n",
            "3. Deep Learning (advanced level)\n",
            "4. Data Processing (intermediate level)\n",
            "5. Evaluation (intermediate level)\n"
          ]
        }
      ],
      "source": [
        "# Create sample documents for testing\n",
        "documents = [\n",
        "    Document(\n",
        "        text=\"\"\"Machine Learning Fundamentals\n",
        "\n",
        "        Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed. It focuses on developing computer programs that can access data and use it to learn for themselves.\n",
        "\n",
        "        The process of learning begins with observations or data, such as examples, direct experience, or instruction, in order to look for patterns in data and make better decisions in the future. The primary aim is to allow computers to learn automatically without human intervention or assistance.\n",
        "        \"\"\",\n",
        "        metadata={\"topic\": \"ML Basics\", \"difficulty\": \"beginner\"}\n",
        "    ),\n",
        "    Document(\n",
        "        text=\"\"\"Types of Machine Learning\n",
        "\n",
        "        There are three main types of machine learning:\n",
        "\n",
        "        1. Supervised Learning: The algorithm learns from labeled training data, helping predict outcomes for unforeseen data. Common applications include classification and regression tasks.\n",
        "\n",
        "        2. Unsupervised Learning: The algorithm learns patterns from unlabeled data. The system tries to learn without a teacher. Common applications include clustering and dimensionality reduction.\n",
        "\n",
        "        3. Reinforcement Learning: The algorithm learns through trial and error, receiving rewards or penalties for actions. It's commonly used in robotics, gaming, and navigation.\n",
        "        \"\"\",\n",
        "        metadata={\"topic\": \"ML Types\", \"difficulty\": \"intermediate\"}\n",
        "    ),\n",
        "    Document(\n",
        "        text=\"\"\"Neural Networks Architecture\n",
        "\n",
        "        Neural networks are computing systems inspired by biological neural networks in animal brains. They consist of interconnected nodes (neurons) organized in layers:\n",
        "\n",
        "        - Input Layer: Receives the initial data\n",
        "        - Hidden Layers: Process information through weighted connections\n",
        "        - Output Layer: Produces the final result\n",
        "\n",
        "        Deep learning uses neural networks with multiple hidden layers, enabling the learning of complex patterns. Each neuron applies an activation function to introduce non-linearity, allowing the network to learn sophisticated relationships in data.\n",
        "        \"\"\",\n",
        "        metadata={\"topic\": \"Deep Learning\", \"difficulty\": \"advanced\"}\n",
        "    ),\n",
        "    Document(\n",
        "        text=\"\"\"Data Preprocessing Techniques\n",
        "\n",
        "        Data preprocessing is a crucial step in machine learning pipelines:\n",
        "\n",
        "        - Data Cleaning: Remove noise, handle missing values, and eliminate duplicates\n",
        "        - Normalization: Scale features to a standard range\n",
        "        - Feature Engineering: Create new features from existing data\n",
        "        - Encoding: Convert categorical variables to numerical format\n",
        "        - Data Splitting: Divide data into training, validation, and test sets\n",
        "\n",
        "        Proper preprocessing significantly impacts model performance and can be the difference between a successful and unsuccessful machine learning project.\n",
        "        \"\"\",\n",
        "        metadata={\"topic\": \"Data Processing\", \"difficulty\": \"intermediate\"}\n",
        "    ),\n",
        "    Document(\n",
        "        text=\"\"\"Model Evaluation Metrics\n",
        "\n",
        "        Evaluating machine learning models requires appropriate metrics:\n",
        "\n",
        "        For Classification:\n",
        "        - Accuracy: Overall correctness of predictions\n",
        "        - Precision: Quality of positive predictions\n",
        "        - Recall: Coverage of actual positive cases\n",
        "        - F1 Score: Harmonic mean of precision and recall\n",
        "\n",
        "        For Regression:\n",
        "        - Mean Squared Error (MSE): Average squared differences\n",
        "        - Root Mean Squared Error (RMSE): Square root of MSE\n",
        "        - R-squared: Proportion of variance explained\n",
        "        - Mean Absolute Error (MAE): Average absolute differences\n",
        "        \"\"\",\n",
        "        metadata={\"topic\": \"Evaluation\", \"difficulty\": \"intermediate\"}\n",
        "    )\n",
        "]\n",
        "\n",
        "print(f\"Created {len(documents)} sample documents\")\n",
        "print(\"\\nDocument topics:\")\n",
        "for i, doc in enumerate(documents, 1):\n",
        "    print(f\"{i}. {doc.metadata['topic']} ({doc.metadata['difficulty']} level)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewvsKe1y_XvM"
      },
      "source": [
        "## Background\n",
        "\n",
        "Before diving into implementation, let's understand the theoretical foundation of advanced retrievers and their role in RAG systems.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Srpk7gvI_XvM"
      },
      "source": [
        "### What are Advanced Retrievers?\n",
        "\n",
        "Advanced retrievers are sophisticated mechanisms that go beyond simple similarity search to find the most relevant information from a knowledge base. While basic retrievers rely solely on vector similarity, advanced retrievers employ multiple strategies:\n",
        "\n",
        "**Core Capabilities:**\n",
        "- **Multi-Strategy Search**: Combine semantic, keyword, and structural approaches\n",
        "- **Hierarchical Understanding**: Navigate document structures intelligently\n",
        "- **Query Enhancement**: Generate and fuse multiple query variations\n",
        "- **Context Preservation**: Maintain document hierarchy and relationships\n",
        "- **Adaptive Ranking**: Use sophisticated scoring mechanisms\n",
        "\n",
        "**Key Differences from Basic Retrieval:**\n",
        "1. Basic: Single embedding similarity → Advanced: Multiple retrieval strategies\n",
        "2. Basic: Flat document structure → Advanced: Hierarchical understanding\n",
        "3. Basic: Single query → Advanced: Query expansion and fusion\n",
        "4. Basic: Fixed chunk size → Advanced: Dynamic context merging\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e24jpP2p_XvM"
      },
      "source": [
        "### Why are Advanced Retrievers Important?\n",
        "\n",
        "Advanced retrievers address critical limitations in production RAG systems:\n",
        "\n",
        "**1. Improved Recall and Precision**\n",
        "- Combine semantic and keyword search to catch different query types\n",
        "- Reduce false negatives through query expansion\n",
        "- Minimize false positives with better ranking\n",
        "\n",
        "**2. Better Context Understanding**\n",
        "- Preserve document structure and hierarchy\n",
        "- Maintain relationships between sections\n",
        "- Provide appropriate context windows\n",
        "\n",
        "**3. Handling Complex Queries**\n",
        "- Multi-faceted questions requiring different retrieval strategies\n",
        "- Queries that benefit from multiple perspectives\n",
        "- Technical queries needing exact keyword matches\n",
        "\n",
        "**4. Production Reliability**\n",
        "- Fallback mechanisms for edge cases\n",
        "- Consistent performance across query types\n",
        "- Scalable to large document collections\n",
        "\n",
        "**Real-World Impact:**\n",
        "- Customer Support: 40% improvement in answer relevance\n",
        "- Legal Research: 60% reduction in missed relevant cases\n",
        "- Technical Documentation: 50% faster information retrieval\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vukvDqvr_XvN"
      },
      "source": [
        "### Index Types Overview\n",
        "\n",
        "LlamaIndex supports various index types, each optimized for different retrieval patterns:\n",
        "\n",
        "**1. Vector Store Index**\n",
        "- **Best For**: Semantic similarity search\n",
        "- **How It Works**: Embeds documents and queries into vector space\n",
        "- **Strengths**: Captures meaning and context\n",
        "- **Use Cases**: General question answering, conceptual queries\n",
        "\n",
        "**2. Keyword/BM25 Index**\n",
        "- **Best For**: Exact term matching\n",
        "- **How It Works**: Statistical ranking based on term frequency\n",
        "- **Strengths**: Precise keyword retrieval, no embedding overhead\n",
        "- **Use Cases**: Technical documentation, legal search, code retrieval\n",
        "\n",
        "**3. Summary Index**\n",
        "- **Best For**: Document-level retrieval\n",
        "- **How It Works**: Creates summaries for document selection\n",
        "- **Strengths**: Intelligent document filtering\n",
        "- **Use Cases**: Multi-document QA, research papers, long-form content\n",
        "\n",
        "**4. Hierarchical Index**\n",
        "- **Best For**: Structured documents\n",
        "- **How It Works**: Maintains parent-child relationships\n",
        "- **Strengths**: Context preservation, dynamic merging\n",
        "- **Use Cases**: Books, technical manuals, structured reports\n",
        "\n",
        "**Choosing the Right Index:**\n",
        "- Single strategy → Simple queries, homogeneous content\n",
        "- Hybrid approach → Production systems, diverse query types\n",
        "- Multi-index → Large-scale systems, specialized content types\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KZiQTXv_XvN"
      },
      "source": [
        "## Core Retriever Demonstrations\n",
        "\n",
        "Now let's implement and test each retriever type with practical examples.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPk_jOL4_XvN"
      },
      "source": [
        "### 1. Vector Index Retriever - The Foundation\n",
        "\n",
        "The Vector Index Retriever is the most common retrieval method, using semantic similarity to find relevant documents.\n",
        "\n",
        "**How It Works:**\n",
        "1. Documents are split into chunks and embedded into vectors\n",
        "2. Queries are embedded using the same model\n",
        "3. Cosine similarity finds the closest vectors\n",
        "4. Top-k most similar chunks are retrieved\n",
        "\n",
        "**Strengths:**\n",
        "- Captures semantic meaning beyond keywords\n",
        "- Handles paraphrasing and synonyms well\n",
        "- Good for conceptual questions\n",
        "\n",
        "**Limitations:**\n",
        "- May miss exact keyword matches\n",
        "- Embedding quality dependent\n",
        "- Computational overhead for embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497,
          "referenced_widgets": [
            "d79a553c87a64b52a56929556ad3ded0",
            "1a7c82e50e7b42999fc8db5c4d4e40d0",
            "56c4893dbfb34dfb9e3544f40b43c151",
            "6e4ce66d78b04d4ba005a3c509f04d4c",
            "1e091864c6794c71a4ed2ca67aed4023",
            "97775a940d184917a365db054d649151",
            "201418a9615f4c9b97fdb62e0075e5b2",
            "f1f1334b1a874501bc77dfff72848e23",
            "22ad8449e0674c1cb7e6e9dae6c2de21",
            "bf60c6d49b224f1882c9a64765acc28f",
            "71ff1c1a0382468ab345cc4f2ebf6572",
            "77e1e1957d0945a6b964fe4b050b67f6",
            "0fc6841dc24d4127a038843cea89fd0b",
            "03b0832a0afd4ceb94c34c2ccabb633e",
            "b005c164465049548c001c933a734255",
            "e7ec56bb35234e7b97c983f2b8e988eb",
            "2d741b9bece6486c82ea6ad1a6c30bd6",
            "0f806b57f8c548ef9bfa3f7926d7c673",
            "44201f7dc5fb4563a5d4505358b9b6d6",
            "c3e3cf4cea634a12b8dd229523e58316",
            "8cd9d07c14b24a11be45d5b8e9936e00",
            "0d3ae7c611734036a9aa446906c3b111"
          ]
        },
        "id": "DVVlmcp7_XvN",
        "outputId": "4090177e-0039-4841-a7fa-3fe7f882dfb6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d79a553c87a64b52a56929556ad3ded0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "77e1e1957d0945a6b964fe4b050b67f6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: How do computers learn without being programmed?\n",
            "\n",
            "Retrieved 3 nodes:\n",
            "\n",
            "Result 1 (Score: 0.6995):\n",
            "Topic: ML Basics\n",
            "Text preview: Machine Learning Fundamentals\n",
            "        \n",
            "        Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed. It...\n",
            "\n",
            "Result 2 (Score: 0.6321):\n",
            "Topic: Deep Learning\n",
            "Text preview: Neural Networks Architecture\n",
            "        \n",
            "        Neural networks are computing systems inspired by biological neural networks in animal brains. They consist of interconnected nodes (neurons) organized in...\n",
            "\n",
            "Result 3 (Score: 0.5991):\n",
            "Topic: ML Types\n",
            "Text preview: Types of Machine Learning\n",
            "        \n",
            "        There are three main types of machine learning:\n",
            "        \n",
            "        1. Supervised Learning: The algorithm learns from labeled training data, helping predict out...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create Vector Store Index\n",
        "vector_index = VectorStoreIndex.from_documents(\n",
        "    documents,\n",
        "    show_progress=True\n",
        ")\n",
        "\n",
        "# Get the retriever\n",
        "vector_retriever = vector_index.as_retriever(\n",
        "    similarity_top_k=3  # Retrieve top 3 most similar chunks\n",
        ")\n",
        "\n",
        "# Test with a semantic query\n",
        "query = \"How do computers learn without being programmed?\"\n",
        "retrieved_nodes = vector_retriever.retrieve(query)\n",
        "\n",
        "print(f\"Query: {query}\\n\")\n",
        "print(f\"Retrieved {len(retrieved_nodes)} nodes:\\n\")\n",
        "\n",
        "for i, node in enumerate(retrieved_nodes, 1):\n",
        "    print(f\"Result {i} (Score: {node.score:.4f}):\")\n",
        "    print(f\"Topic: {node.metadata.get('topic', 'N/A')}\")\n",
        "    print(f\"Text preview: {node.text[:200]}...\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4dHDQvV_XvN"
      },
      "source": [
        "### 2. BM25 Retriever - Advanced Keyword-Based Search\n",
        "\n",
        "BM25 (Best Matching 25) is a probabilistic ranking function that excels at keyword-based retrieval.\n",
        "\n",
        "**How It Works:**\n",
        "1. Tokenizes documents and queries\n",
        "2. Applies stemming to normalize words\n",
        "3. Calculates term frequency (TF) and inverse document frequency (IDF)\n",
        "4. Ranks documents using BM25 scoring formula\n",
        "\n",
        "**Strengths:**\n",
        "- Excellent for exact term matching\n",
        "- No embedding model required\n",
        "- Fast and efficient\n",
        "- Great for technical/domain-specific terms\n",
        "\n",
        "**Use Cases:**\n",
        "- Legal document search\n",
        "- Code retrieval\n",
        "- Technical documentation\n",
        "- When exact terminology matters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0mJdJc4_XvN",
        "outputId": "6eb5a47a-d20b-43c8-cd03-ccf0dd07d24a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:bm25s:Building index from IDs objects\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 9 nodes for BM25 indexing.\n",
            "\n",
            "Query: supervised learning classification regression\n",
            "\n",
            "Retrieved 3 nodes:\n",
            "\n",
            "Result 1 (Score: 1.8734)\n",
            "Topic: ML Types\n",
            "Text: Types of Machine Learning\n",
            "        \n",
            "        There are three main types of machine learning:\n",
            "        \n",
            "        1. Supervised Learning: The algorithm learns from labeled training data, helping predict outcomes for unforeseen data. Common applications include classification and regression tasks.\n",
            "        \n",
            "        2. Unsupervised Learning: The algorithm learns patterns from unlabeled data. The system tries to learn without a teacher. Common applications include clustering and dimensionality reduction.\n",
            "        \n",
            "        3.\n",
            "\n",
            "Result 2 (Score: 0.7301)\n",
            "Topic: Evaluation\n",
            "Text: Model Evaluation Metrics\n",
            "        \n",
            "        Evaluating machine learning models requires appropriate metrics:\n",
            "        \n",
            "        For Classification:\n",
            "        - Accuracy: Overall correctness of predictions\n",
            "        - Precision: Quality of positive predictions\n",
            "        - Recall: Coverage of actual positive cases\n",
            "        - F1 Score: Harmonic mean of\n",
            "\n",
            "Result 3 (Score: 0.5971)\n",
            "Topic: Evaluation\n",
            "Text: - F1 Score: Harmonic mean of precision and recall\n",
            "        \n",
            "        For Regression:\n",
            "        - Mean Squared Error (MSE): Average squared differences\n",
            "        - Root Mean Squared Error (RMSE): Square root of MSE\n",
            "        - R-squared: Proportion of variance explained\n",
            "        - Mean Absolute Error\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.retrievers.bm25 import BM25Retriever\n",
        "import Stemmer\n",
        "\n",
        "parser = SentenceSplitter(\n",
        "    chunk_size=115,\n",
        "    chunk_overlap=15\n",
        ")\n",
        "\n",
        "nodes = parser.get_nodes_from_documents(documents)\n",
        "\n",
        "print(f\"Created {len(nodes)} nodes for BM25 indexing.\\n\")\n",
        "\n",
        "\n",
        "# 2)Initialize BM25 Retriever\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_defaults(\n",
        "    nodes=nodes,\n",
        "    similarity_top_k=3,\n",
        "    stemmer=Stemmer.Stemmer(\"english\"),\n",
        "    language=\"english\"\n",
        ")\n",
        "\n",
        "\n",
        "#Test Query\n",
        "\n",
        "query = \"supervised learning classification regression\"\n",
        "\n",
        "retrieved_nodes = bm25_retriever.retrieve(query)\n",
        "\n",
        "print(f\"Query: {query}\\n\")\n",
        "print(f\"Retrieved {len(retrieved_nodes)} nodes:\\n\")\n",
        "\n",
        "for i, node in enumerate(retrieved_nodes, 1):\n",
        "    print(f\"Result {i} (Score: {node.score:.4f})\")\n",
        "    print(f\"Topic: {node.metadata.get('topic', 'N/A')}\")\n",
        "    print(f\"Text: {node.text}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_I2aj3H_XvN"
      },
      "source": [
        "### 3. Document Summary Index Retrievers\n",
        "\n",
        "Document Summary Index creates summaries of documents and uses them for initial selection, enabling more intelligent document-level retrieval.\n",
        "\n",
        "**How It Works:**\n",
        "1. Generates a summary for each document using an LLM\n",
        "2. Uses summaries for initial document selection\n",
        "3. Retrieves from selected documents\n",
        "\n",
        "**Strengths:**\n",
        "- Intelligent document pre-filtering\n",
        "- Reduces search space\n",
        "- Better for multi-document scenarios\n",
        "\n",
        "**Best For:**\n",
        "- Research paper collections\n",
        "- Multi-document QA\n",
        "- Large document sets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451,
          "referenced_widgets": [
            "e4c210b25eb0485890438d0b38d51ecd",
            "2d6485bef00a4590a682159ebba24e89",
            "796835f92d1e4f0fb6964fe2d73f9a6b",
            "e6cba5a45192446684a547c54c397ea5",
            "1ad3f219eba4445bbc929bc7cf4dabef",
            "55439043425447acb125bc9249136444",
            "b092480b6d6049adad5e1a4db8d18486",
            "0bbbe92a0b6a4275996e8b0fc961a048",
            "334d194db06d40f09c00ab3590e448ec",
            "7c7227894d924b599c6fc0b8ef469a54",
            "c8816f14aab94155b7245b6a00271ffe"
          ]
        },
        "id": "LYRZiyoe_XvN",
        "outputId": "b139c76a-0e0c-4709-85ba-bc0724dbdcfa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Parsing nodes:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4c210b25eb0485890438d0b38d51ecd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What are the main concepts in machine learning?\n",
            "\n",
            "Response: Machine learning is a field within artificial intelligence that allows systems to learn and improve from experience without being explicitly programmed. It involves developing computer programs that can access data, identify patterns, and use this understanding to make future decisions automatically.\n",
            "\n",
            "The primary approaches to machine learning include:\n",
            "*   **Supervised Learning**, where algorithms learn from labeled data to predict outcomes.\n",
            "*   **Unsupervised Learning**, which involves discovering patterns in unlabeled data without explicit guidance.\n",
            "*   **Reinforcement Learning**, where algorithms learn through trial and error, receiving feedback in the form of rewards or penalties.\n",
            "\n",
            "A crucial step in the machine learning process is **data preprocessing**, which involves techniques such as cleaning data, normalizing features, engineering new features, encoding categorical variables, and splitting data into training, validation, and test sets.\n",
            "\n",
            "Advanced machine learning often utilizes **neural networks**, which are computing systems inspired by biological brains. These networks consist of interconnected layers of nodes, including an input layer, hidden layers for processing, and an output layer for results. Deep learning, in particular, employs neural networks with multiple hidden layers to learn intricate patterns.\n",
            "\n",
            "Finally, **model evaluation** is essential to assess performance. This involves using specific metrics, such as accuracy, precision, recall, and F1 score for classification tasks, and mean squared error, root mean squared error, R-squared, and mean absolute error for regression tasks.\n",
            "\n",
            "\n",
            "Source nodes used: 5\n",
            "1. ML Basics\n",
            "2. ML Types\n",
            "3. Deep Learning\n",
            "4. Data Processing\n",
            "5. Evaluation\n"
          ]
        }
      ],
      "source": [
        "# Create Summary Index\n",
        "summary_index = SummaryIndex.from_documents(\n",
        "    documents,\n",
        "    show_progress=True\n",
        ")\n",
        "\n",
        "# Create query engine from summary index\n",
        "summary_query_engine = summary_index.as_query_engine(\n",
        "    response_mode=\"tree_summarize\"\n",
        ")\n",
        "\n",
        "# Test with a broad query\n",
        "query = \"What are the main concepts in machine learning?\"\n",
        "response = summary_query_engine.query(query)\n",
        "\n",
        "print(f\"Query: {query}\\n\")\n",
        "print(f\"Response: {response}\\n\")\n",
        "print(f\"\\nSource nodes used: {len(response.source_nodes)}\")\n",
        "for i, node in enumerate(response.source_nodes, 1):\n",
        "    print(f\"{i}. {node.metadata.get('topic', 'N/A')}\")\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XriaYiX0_XvO"
      },
      "source": [
        "### 4. Auto-Merging Retriever - Hierarchical Context Preservation\n",
        "\n",
        "Auto-Merging Retriever maintains document hierarchy and intelligently merges chunks when multiple child chunks from the same parent are retrieved.\n",
        "\n",
        "**How It Works:**\n",
        "1. Documents are parsed into hierarchical chunks (parent-child relationships)\n",
        "2. Retrieval happens at the child level (smaller chunks)\n",
        "3. If multiple children from same parent are retrieved, they're merged\n",
        "4. Provides more complete context automatically\n",
        "\n",
        "**Strengths:**\n",
        "- Preserves document structure\n",
        "- Automatic context expansion\n",
        "- Better coherence in responses\n",
        "\n",
        "**Use Cases:**\n",
        "- Books and long-form content\n",
        "- Technical manuals\n",
        "- Structured documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izyEsgwD_XvO",
        "outputId": "73d9c245-58e5-4e53-eca9-db032c1bcd12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 16 hierarchical nodes\n",
            "\n",
            "Vector index built successfully\n",
            "\n",
            "Auto-merging retriever initialized\n",
            "\n",
            "> Merging 1 nodes into parent node.\n",
            "> Parent node id: d6593846-7f7c-429f-86fc-030124a52ca9.\n",
            "> Parent node text: Machine Learning Fundamentals\n",
            "        \n",
            "        Machine learning is a subset of artificial intelli...\n",
            "\n",
            "Query: Explain the types of machine learning\n",
            "\n",
            "Retrieved 3 merged nodes:\n",
            "\n",
            "Node 1\n",
            "Topic: ML Types\n",
            "Text Length: 633 characters\n",
            "Preview: Types of Machine Learning\n",
            "        \n",
            "        There are three main types of machine learning:\n",
            "        \n",
            "        1. Supervised Learning: The algorithm lear...\n",
            "\n",
            "Node 2\n",
            "Topic: ML Types\n",
            "Text Length: 689 characters\n",
            "Preview: Types of Machine Learning\n",
            "        \n",
            "        There are three main types of machine learning:\n",
            "        \n",
            "        1. Supervised Learning: The algorithm lear...\n",
            "\n",
            "Node 3\n",
            "Topic: ML Basics\n",
            "Text Length: 607 characters\n",
            "Preview: Machine Learning Fundamentals\n",
            "        \n",
            "        Machine learning is a subset of artificial intelligence that enables systems to learn and improve from ...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core.node_parser import HierarchicalNodeParser\n",
        "from llama_index.core import StorageContext, VectorStoreIndex\n",
        "from llama_index.core.retrievers import AutoMergingRetriever\n",
        "\n",
        "\n",
        "# Create hierarchical nodes\n",
        "node_parser = HierarchicalNodeParser.from_defaults(\n",
        "    chunk_sizes=[512, 256, 128]\n",
        ")\n",
        "\n",
        "hierarchical_nodes = node_parser.get_nodes_from_documents(documents)\n",
        "\n",
        "print(f\"Created {len(hierarchical_nodes)} hierarchical nodes\\n\")\n",
        "\n",
        "\n",
        "# Create storage context\n",
        "storage_context = StorageContext.from_defaults()\n",
        "storage_context.docstore.add_documents(hierarchical_nodes)\n",
        "\n",
        "\n",
        "# Build vector index\n",
        "hierarchical_index = VectorStoreIndex(\n",
        "    hierarchical_nodes,\n",
        "    storage_context=storage_context\n",
        ")\n",
        "\n",
        "print(\"Vector index built successfully\\n\")\n",
        "\n",
        "\n",
        "# Create auto-merging retriever\n",
        "base_retriever = hierarchical_index.as_retriever(\n",
        "    similarity_top_k=6\n",
        ")\n",
        "\n",
        "auto_merging_retriever = AutoMergingRetriever(\n",
        "    base_retriever,\n",
        "    storage_context=storage_context,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"Auto-merging retriever initialized\\n\")\n",
        "\n",
        "\n",
        "# Test query\n",
        "query = \"Explain the types of machine learning\"\n",
        "\n",
        "retrieved_nodes = auto_merging_retriever.retrieve(query)\n",
        "\n",
        "print(f\"Query: {query}\\n\")\n",
        "print(f\"Retrieved {len(retrieved_nodes)} merged nodes:\\n\")\n",
        "\n",
        "for i, node in enumerate(retrieved_nodes, 1):\n",
        "    print(f\"Node {i}\")\n",
        "    print(f\"Topic: {node.metadata.get('topic', 'N/A')}\")\n",
        "    print(f\"Text Length: {len(node.text)} characters\")\n",
        "    print(f\"Preview: {node.text[:150]}...\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YV_fkl5w_XvO"
      },
      "source": [
        "### 5. Recursive Retriever - Multi-Level Reference Following\n",
        "\n",
        "Recursive Retriever can follow references and retrieve from multiple levels of document structure.\n",
        "\n",
        "**How It Works:**\n",
        "1. Initial retrieval from index nodes (high-level references)\n",
        "2. Recursively retrieves from referenced underlying indices\n",
        "3. Aggregates results from multiple levels\n",
        "\n",
        "**Strengths:**\n",
        "- Handles complex document structures\n",
        "- Follows cross-references\n",
        "- Multi-level aggregation\n",
        "\n",
        "**Use Cases:**\n",
        "- Cross-referenced documents\n",
        "- Multi-index systems\n",
        "- Hierarchical knowledge bases\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6KbOyvB_XvO",
        "outputId": "3b70ca67-7970-4dfa-efa8-0a7d8f16828e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;3;34mRetrieving with query id None: What is supervised learning?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: ml_index\n",
            "\u001b[0m\u001b[1;3;34mRetrieving with query id ml_index: What is supervised learning?\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieving text node: Machine Learning Fundamentals\n",
            "        \n",
            "        Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed. It focuses on developing computer programs that can access data and use it to learn for themselves.\n",
            "        \n",
            "        The process of learning begins with observations or data, such as examples, direct experience, or instruction, in order to look for patterns in data and make better decisions in the future. The primary aim is to allow computers to learn automatically without human intervention or assistance.\n",
            "\u001b[0m\u001b[1;3;38;5;200mRetrieving text node: Types of Machine Learning\n",
            "        \n",
            "        There are three main types of machine learning:\n",
            "        \n",
            "        1. Supervised Learning: The algorithm learns from labeled training data, helping predict outcomes for unforeseen data. Common applications include classification and regression tasks.\n",
            "        \n",
            "        2. Unsupervised Learning: The algorithm learns patterns from unlabeled data. The system tries to learn without a teacher. Common applications include clustering and dimensionality reduction.\n",
            "        \n",
            "        3. Reinforcement Learning: The algorithm learns through trial and error, receiving rewards or penalties for actions. It's commonly used in robotics, gaming, and navigation.\n",
            "\u001b[0m\n",
            "Query: What is supervised learning?\n",
            "\n",
            "Retrieved 2 nodes via recursive routing:\n",
            "\n",
            "Node 1\n",
            "Score: 0.7356\n",
            "Topic: ML Basics\n",
            "Preview: Machine Learning Fundamentals\n",
            "        \n",
            "        Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed. It...\n",
            "\n",
            "Node 2\n",
            "Score: 0.7317\n",
            "Topic: ML Types\n",
            "Preview: Types of Machine Learning\n",
            "        \n",
            "        There are three main types of machine learning:\n",
            "        \n",
            "        1. Supervised Learning: The algorithm learns from labeled training data, helping predict out...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "from llama_index.core.schema import IndexNode\n",
        "from llama_index.core.retrievers import RecursiveRetriever\n",
        "\n",
        "\n",
        "# Split documents\n",
        "ml_docs = [doc for doc in documents if \"ML\" in doc.metadata.get(\"topic\", \"\")]\n",
        "advanced_docs = [doc for doc in documents if \"ML\" not in doc.metadata.get(\"topic\", \"\")]\n",
        "\n",
        "\n",
        "# Create sub-indices\n",
        "ml_index = VectorStoreIndex.from_documents(ml_docs)\n",
        "advanced_index = VectorStoreIndex.from_documents(advanced_docs)\n",
        "\n",
        "\n",
        "# Create router nodes\n",
        "router_nodes = [\n",
        "    IndexNode(\n",
        "        text=\"Covers machine learning fundamentals and types including supervised and unsupervised learning.\",\n",
        "        index_id=\"ml_index\"\n",
        "    ),\n",
        "    IndexNode(\n",
        "        text=\"Covers neural networks, preprocessing, and evaluation metrics.\",\n",
        "        index_id=\"advanced_index\"\n",
        "    )\n",
        "]\n",
        "\n",
        "\n",
        "# Create top-level index\n",
        "top_index = VectorStoreIndex(router_nodes)\n",
        "\n",
        "\n",
        "# Create recursive retriever\n",
        "recursive_retriever = RecursiveRetriever(\n",
        "    root_id=\"vector\",\n",
        "    retriever_dict={\n",
        "        \"vector\": top_index.as_retriever(similarity_top_k=1),\n",
        "        \"ml_index\": ml_index.as_retriever(similarity_top_k=3),\n",
        "        \"advanced_index\": advanced_index.as_retriever(similarity_top_k=3),\n",
        "    },\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "\n",
        "# Test query\n",
        "query = \"What is supervised learning?\"\n",
        "\n",
        "results = recursive_retriever.retrieve(query)\n",
        "\n",
        "print(f\"\\nQuery: {query}\\n\")\n",
        "print(f\"Retrieved {len(results)} nodes via recursive routing:\\n\")\n",
        "\n",
        "for i, node in enumerate(results, 1):\n",
        "    print(f\"Node {i}\")\n",
        "    print(f\"Score: {node.score:.4f}\")\n",
        "    print(f\"Topic: {node.metadata.get('topic', 'N/A')}\")\n",
        "    print(f\"Preview: {node.text[:200]}...\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9JqLJM__XvO"
      },
      "source": [
        "### 6. Query Fusion Retriever - Multi-Query Enhancement with Advanced Fusion\n",
        "\n",
        "Query Fusion Retriever generates multiple query variations and combines results using sophisticated fusion techniques.\n",
        "\n",
        "**How It Works:**\n",
        "1. Generates multiple query variations using an LLM\n",
        "2. Retrieves results for each query variation\n",
        "3. Fuses results using one of three strategies:\n",
        "   - **Reciprocal Rank Fusion (RRF)**: Combines based on rank positions\n",
        "   - **Relative Score Fusion**: Normalizes and combines scores\n",
        "   - **Distribution-Based Fusion**: Uses score distributions\n",
        "\n",
        "**Strengths:**\n",
        "- Handles ambiguous queries\n",
        "- Improves recall\n",
        "- Multiple perspectives\n",
        "\n",
        "**Fusion Methods Compared:**\n",
        "\n",
        "**Reciprocal Rank Fusion (RRF):**\n",
        "- Formula: `score = Σ(1 / (k + rank))` where k=60 (typical)\n",
        "- Focuses on rank position, not raw scores\n",
        "- Good when different retrievers have incomparable scores\n",
        "- Example: If doc appears at rank 1 in one query and rank 3 in another:\n",
        "  - RRF score = 1/(60+1) + 1/(60+3) ≈ 0.0164 + 0.0159 = 0.0323\n",
        "\n",
        "**Relative Score Fusion:**\n",
        "- Normalizes scores to [0,1] range for each query\n",
        "- Takes mean of normalized scores across queries\n",
        "- Better when scores are meaningful within each retrieval\n",
        "- Example: Raw scores [0.8, 0.6, 0.4] normalized to [1.0, 0.5, 0.0]\n",
        "\n",
        "**Distribution-Based Fusion:**\n",
        "- Uses statistical distribution of scores\n",
        "- Considers mean and standard deviation\n",
        "- Good for handling outliers and score variance\n",
        "- Example: Weights based on how many standard deviations above mean\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0mCiuki4_XvO",
        "outputId": "9ddc085e-541c-4d3f-be05-dbdae3233b45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing RRF Fusion with query: How can I improve model accuracy?\n",
            "\n",
            "Generated queries:\n",
            "Machine learning model accuracy improvement techniques\n",
            "Strategies for enhancing predictive model performance\n",
            "\n",
            "Retrieved 3 nodes with RRF:\n",
            "\n",
            "Node 1 (Score: 0.0817):\n",
            "Topic: Data Processing\n",
            "Preview: Data Preprocessing Techniques\n",
            "        \n",
            "        Data preprocessing is a crucial step in machine learning pipelines:\n",
            "        \n",
            "        - Data Cleaning: R...\n",
            "\n",
            "Node 2 (Score: 0.0500):\n",
            "Topic: Evaluation\n",
            "Preview: Model Evaluation Metrics\n",
            "        \n",
            "        Evaluating machine learning models requires appropriate metrics:\n",
            "        \n",
            "        For Classification:\n",
            "      ...\n",
            "\n",
            "Node 3 (Score: 0.0500):\n",
            "Topic: Evaluation\n",
            "Preview: Model Evaluation Metrics\n",
            "        \n",
            "        Evaluating machine learning models requires appropriate metrics:\n",
            "        \n",
            "        For Classification:\n",
            "      ...\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Testing Relative Score Fusion with query: How can I improve model accuracy?\n",
            "\n",
            "Generated queries:\n",
            "Strategies for enhancing AI model accuracy\n",
            "Common reasons for low model accuracy and solutions\n",
            "\n",
            "Retrieved 3 nodes with Relative Score:\n",
            "\n",
            "Node 1 (Score: 0.5000):\n",
            "Topic: Evaluation\n",
            "Preview: Model Evaluation Metrics\n",
            "        \n",
            "        Evaluating machine learning models requires appropriate metrics:\n",
            "        \n",
            "        For Classification:\n",
            "      ...\n",
            "\n",
            "Node 2 (Score: 0.5000):\n",
            "Topic: Evaluation\n",
            "Preview: Model Evaluation Metrics\n",
            "        \n",
            "        Evaluating machine learning models requires appropriate metrics:\n",
            "        \n",
            "        For Classification:\n",
            "      ...\n",
            "\n",
            "Node 3 (Score: 0.0580):\n",
            "Topic: ML Basics\n",
            "Preview: Machine Learning Fundamentals\n",
            "        \n",
            "        Machine learning is a subset of artificial intelligence that enables systems to learn and improve from ...\n",
            "\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Testing Distribution-Based Fusion with query: How can I improve model accuracy?\n",
            "\n",
            "Generated queries:\n",
            "Techniques to improve machine learning model accuracy\n",
            "Strategies for enhancing model performance\n",
            "\n",
            "Retrieved 3 nodes with Distribution-Based:\n",
            "\n",
            "Node 1 (Score: 0.3694):\n",
            "Topic: Data Processing\n",
            "Preview: Data Preprocessing Techniques\n",
            "        \n",
            "        Data preprocessing is a crucial step in machine learning pipelines:\n",
            "        \n",
            "        - Data Cleaning: R...\n",
            "\n",
            "Node 2 (Score: 0.3678):\n",
            "Topic: Evaluation\n",
            "Preview: Model Evaluation Metrics\n",
            "        \n",
            "        Evaluating machine learning models requires appropriate metrics:\n",
            "        \n",
            "        For Classification:\n",
            "      ...\n",
            "\n",
            "Node 3 (Score: 0.3392):\n",
            "Topic: Evaluation\n",
            "Preview: Model Evaluation Metrics\n",
            "        \n",
            "        Evaluating machine learning models requires appropriate metrics:\n",
            "        \n",
            "        For Classification:\n",
            "      ...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create query fusion retriever with RRF\n",
        "fusion_retriever_rrf = QueryFusionRetriever(\n",
        "    retrievers=[vector_retriever, bm25_retriever],\n",
        "    similarity_top_k=3,\n",
        "    num_queries=3,  # Generate 3 query variations\n",
        "    mode=\"reciprocal_rerank\",  # RRF fusion\n",
        "    use_async=False,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Test with an ambiguous query\n",
        "query = \"How can I improve model accuracy?\"\n",
        "print(f\"Testing RRF Fusion with query: {query}\\n\")\n",
        "retrieved_nodes_rrf = fusion_retriever_rrf.retrieve(query)\n",
        "\n",
        "print(f\"\\nRetrieved {len(retrieved_nodes_rrf)} nodes with RRF:\\n\")\n",
        "for i, node in enumerate(retrieved_nodes_rrf, 1):\n",
        "    print(f\"Node {i} (Score: {node.score:.4f}):\")\n",
        "    print(f\"Topic: {node.metadata.get('topic', 'N/A')}\")\n",
        "    print(f\"Preview: {node.text[:150]}...\\n\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# Create query fusion retriever with Relative Score Fusion\n",
        "fusion_retriever_relative = QueryFusionRetriever(\n",
        "    retrievers=[vector_retriever, bm25_retriever],\n",
        "    similarity_top_k=3,\n",
        "    num_queries=3,\n",
        "    mode=\"relative_score\",  # Relative score fusion\n",
        "    use_async=False,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(f\"Testing Relative Score Fusion with query: {query}\\n\")\n",
        "retrieved_nodes_relative = fusion_retriever_relative.retrieve(query)\n",
        "\n",
        "print(f\"\\nRetrieved {len(retrieved_nodes_relative)} nodes with Relative Score:\\n\")\n",
        "for i, node in enumerate(retrieved_nodes_relative, 1):\n",
        "    print(f\"Node {i} (Score: {node.score:.4f}):\")\n",
        "    print(f\"Topic: {node.metadata.get('topic', 'N/A')}\")\n",
        "    print(f\"Preview: {node.text[:150]}...\\n\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "\n",
        "# Create query fusion retriever with Distribution-Based Fusion\n",
        "fusion_retriever_dist = QueryFusionRetriever(\n",
        "    retrievers=[vector_retriever, bm25_retriever],\n",
        "    similarity_top_k=3,\n",
        "    num_queries=3,\n",
        "    mode=\"dist_based_score\",  # Distribution-based fusion\n",
        "    use_async=False,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(f\"Testing Distribution-Based Fusion with query: {query}\\n\")\n",
        "retrieved_nodes_dist = fusion_retriever_dist.retrieve(query)\n",
        "\n",
        "print(f\"\\nRetrieved {len(retrieved_nodes_dist)} nodes with Distribution-Based:\\n\")\n",
        "for i, node in enumerate(retrieved_nodes_dist, 1):\n",
        "    print(f\"Node {i} (Score: {node.score:.4f}):\")\n",
        "    print(f\"Topic: {node.metadata.get('topic', 'N/A')}\")\n",
        "    print(f\"Preview: {node.text[:150]}...\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfuDWLSE_XvO"
      },
      "source": [
        "**Choosing the Right Fusion Mode:**\n",
        "\n",
        "- **Use RRF when**:\n",
        "  - Combining retrievers with different scoring scales\n",
        "  - You trust ranking more than absolute scores\n",
        "  - Scores across retrievers aren't directly comparable\n",
        "\n",
        "- **Use Relative Score when**:\n",
        "  - Scores within each retriever are meaningful\n",
        "  - You want to preserve relative quality differences\n",
        "  - Retrievers have similar scoring mechanisms\n",
        "\n",
        "- **Use Distribution-Based when**:\n",
        "  - Dealing with varying score distributions\n",
        "  - Need to handle outliers gracefully\n",
        "  - Want statistical normalization\n",
        "\n",
        "In practice, **RRF is the most commonly used** as it's robust and works well across different retriever combinations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sflJKm3_XvP"
      },
      "source": [
        "## Summary\n",
        "\n",
        "**Key Concepts:**\n",
        "- **Vector Index Retriever**: Semantic search using embeddings\n",
        "- **BM25 Retriever**: Advanced keyword-based search with TF-IDF improvements\n",
        "- **Document Summary Index**: Intelligent document selection using summaries\n",
        "- **Auto Merging Retriever**: Hierarchical context preservation\n",
        "- **Recursive Retriever**: Multi-level reference following\n",
        "- **Query Fusion Retriever**: Multi-query enhancement with three fusion modes\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "runtime_attributes": {
        "runtime_version": "2026.01"
      }
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d79a553c87a64b52a56929556ad3ded0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a7c82e50e7b42999fc8db5c4d4e40d0",
              "IPY_MODEL_56c4893dbfb34dfb9e3544f40b43c151",
              "IPY_MODEL_6e4ce66d78b04d4ba005a3c509f04d4c"
            ],
            "layout": "IPY_MODEL_1e091864c6794c71a4ed2ca67aed4023"
          }
        },
        "1a7c82e50e7b42999fc8db5c4d4e40d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97775a940d184917a365db054d649151",
            "placeholder": "​",
            "style": "IPY_MODEL_201418a9615f4c9b97fdb62e0075e5b2",
            "value": "Parsing nodes: 100%"
          }
        },
        "56c4893dbfb34dfb9e3544f40b43c151": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1f1334b1a874501bc77dfff72848e23",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22ad8449e0674c1cb7e6e9dae6c2de21",
            "value": 5
          }
        },
        "6e4ce66d78b04d4ba005a3c509f04d4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf60c6d49b224f1882c9a64765acc28f",
            "placeholder": "​",
            "style": "IPY_MODEL_71ff1c1a0382468ab345cc4f2ebf6572",
            "value": " 5/5 [00:00&lt;00:00, 129.71it/s]"
          }
        },
        "1e091864c6794c71a4ed2ca67aed4023": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97775a940d184917a365db054d649151": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "201418a9615f4c9b97fdb62e0075e5b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1f1334b1a874501bc77dfff72848e23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22ad8449e0674c1cb7e6e9dae6c2de21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf60c6d49b224f1882c9a64765acc28f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71ff1c1a0382468ab345cc4f2ebf6572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "77e1e1957d0945a6b964fe4b050b67f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0fc6841dc24d4127a038843cea89fd0b",
              "IPY_MODEL_03b0832a0afd4ceb94c34c2ccabb633e",
              "IPY_MODEL_b005c164465049548c001c933a734255"
            ],
            "layout": "IPY_MODEL_e7ec56bb35234e7b97c983f2b8e988eb"
          }
        },
        "0fc6841dc24d4127a038843cea89fd0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d741b9bece6486c82ea6ad1a6c30bd6",
            "placeholder": "​",
            "style": "IPY_MODEL_0f806b57f8c548ef9bfa3f7926d7c673",
            "value": "Generating embeddings: 100%"
          }
        },
        "03b0832a0afd4ceb94c34c2ccabb633e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44201f7dc5fb4563a5d4505358b9b6d6",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3e3cf4cea634a12b8dd229523e58316",
            "value": 5
          }
        },
        "b005c164465049548c001c933a734255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cd9d07c14b24a11be45d5b8e9936e00",
            "placeholder": "​",
            "style": "IPY_MODEL_0d3ae7c611734036a9aa446906c3b111",
            "value": " 5/5 [00:00&lt;00:00, 62.42it/s]"
          }
        },
        "e7ec56bb35234e7b97c983f2b8e988eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d741b9bece6486c82ea6ad1a6c30bd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f806b57f8c548ef9bfa3f7926d7c673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44201f7dc5fb4563a5d4505358b9b6d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3e3cf4cea634a12b8dd229523e58316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8cd9d07c14b24a11be45d5b8e9936e00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d3ae7c611734036a9aa446906c3b111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4c210b25eb0485890438d0b38d51ecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d6485bef00a4590a682159ebba24e89",
              "IPY_MODEL_796835f92d1e4f0fb6964fe2d73f9a6b",
              "IPY_MODEL_e6cba5a45192446684a547c54c397ea5"
            ],
            "layout": "IPY_MODEL_1ad3f219eba4445bbc929bc7cf4dabef"
          }
        },
        "2d6485bef00a4590a682159ebba24e89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55439043425447acb125bc9249136444",
            "placeholder": "​",
            "style": "IPY_MODEL_b092480b6d6049adad5e1a4db8d18486",
            "value": "Parsing nodes: 100%"
          }
        },
        "796835f92d1e4f0fb6964fe2d73f9a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bbbe92a0b6a4275996e8b0fc961a048",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_334d194db06d40f09c00ab3590e448ec",
            "value": 5
          }
        },
        "e6cba5a45192446684a547c54c397ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c7227894d924b599c6fc0b8ef469a54",
            "placeholder": "​",
            "style": "IPY_MODEL_c8816f14aab94155b7245b6a00271ffe",
            "value": " 5/5 [00:00&lt;00:00, 154.85it/s]"
          }
        },
        "1ad3f219eba4445bbc929bc7cf4dabef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55439043425447acb125bc9249136444": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b092480b6d6049adad5e1a4db8d18486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0bbbe92a0b6a4275996e8b0fc961a048": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "334d194db06d40f09c00ab3590e448ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c7227894d924b599c6fc0b8ef469a54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8816f14aab94155b7245b6a00271ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}